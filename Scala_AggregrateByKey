#Aggregate By Key 

#Practice 1
#Get the count of Pet's in the house 
#List has two columns ,First one is the Pet category & Second one is age of pets  in house

------------------------------
| Pet category | Age of Pet  |
------------------------------
scala> val home = sc.parallelize(List( ("cat","2"), ("cat", "5"), ("mouse", "4"),("cat", "12"), ("dog", "12"), ("mouse", "2")), 2)
home: org.apache.spark.rdd.RDD[(String, String)] = ParallelCollectionRDD[4] at parallelize at <console>:28

#Placed in the map <k,v> = <pet category, age of pets>
scala> val petMap = home.map(x=>(x._1,x._2.toInt))
map: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[6] at map at <console>:30

#Counting the Pets available in house 
scala> val petCount= petMap.aggregateByKey(0)((x,y)=>x+1,(x,y)=>x+y)
agg: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[7] at aggregateByKey at <console>:32

scala> map.collect.foreach(println)
(cat,2)
(cat,5)
(mouse,4)
(cat,12)
(dog,12)
(mouse,2)

scala> agg.collect.foreach(println)
(dog,1)                                                                         
(cat,3)
(mouse,2)

#Practice 2

#Summing the Pets age available in house 
scala> val petAge= petMap.aggregateByKey(0)((x,y)=>x+y,(x,y)=>x+y)
agg2: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[9] at aggregateByKey at <console>:32

scala> agg2.collect.foreach(println)
(dog,12)                                                                        
(cat,19)
(mouse,6)

#practice 3
#Summing the Pets age available in house 

#List has three columns ,First one is the Pet category & Second one is Price of pet & third filed is age of pets  in house

---------------------------------------------
| Pet category | Price of pet  | Age of Pet |
---------------------------------------------
scala> val data = sc.parallelize(List( ("cat","2","1"), ("cat","2","5"), ("mouse","1", "4"),("cat","2", "12"), ("dog","3", "12"), ("mouse","1","2")), 2)
data: org.apache.spark.rdd.RDD[(String, String, String)] = ParallelCollectionRDD[46] at parallelize at <console>:27

#map (k,(v1,v2)) format 
scala> val map =data.map(x=>(x._1,(x._2,x._3))
     | )
map: org.apache.spark.rdd.RDD[(String, (String, String))] = MapPartitionsRDD[47] at map at <console>:29

scala> map.collect().foreach(println)
(cat,(2,1))                                                                     
(cat,(2,5))
(mouse,(1,4))
(cat,(2,12))
(dog,(3,12))
(mouse,(1,2))

 #calculate the price & age of the w.r.t pets category                                                          

scala> val agg2= map.aggregateByKey((0,0))((x,y)=>(x._1+y._1,x._2+y._2),(x,y)=>(x._1+y._1,x._2+y._2))
agg2: org.apache.spark.rdd.RDD[(String, (Int, Int))] = ShuffledRDD[49] at aggregateByKey at <console>:31

                                    

scala> agg2.collect().foreach(println)
(dog,(3,12))
(cat,(6,18))
(mouse,(2,6))

scala> 


